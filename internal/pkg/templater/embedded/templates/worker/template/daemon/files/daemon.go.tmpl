package {{ .Worker.Name }}

import (
	"context"
	"time"
	"golang.org/x/sync/errgroup"
	"runtime/debug"
	"errors"
	"strings"

	"github.com/prometheus/client_golang/prometheus"
	"github.com/Educentr/go-onlineconf/pkg/onlineconf"
	{{ .Logger.Import }}

	"{{ .ProjectPath }}/pkg/app/daemon"
	"github.com/Educentr/go-project-starter-runtime/pkg/ds"
	"github.com/Educentr/go-project-starter-runtime/pkg/logger"
	"github.com/Educentr/go-project-starter-runtime/pkg/reqctx"
	"{{ .ProjectPath }}/internal/app/constant"
)

type Worker struct {
	daemon.EmptyWorker
	Srv ds.IService
	jobState any
}

const (
	DefaultBatchSize     = 100
	ErrorTimeout         = time.Second * 10
	NextIterationTimeout = time.Millisecond * 1
	NewCycleTimeout      = time.Second * 10
)

const (
	nameFieldLogger = "Name"
	WorkerName      = "{{ .Worker.Name }}"
)

func Create() *Worker {
    return &Worker{}
}

func (w *Worker) Name() string {
	return WorkerName
}

func (w *Worker) Init(ctx context.Context, serviceName, _ string, metrics *prometheus.Registry, srv ds.IService) error {
	w.Srv = srv
	return nil
}

func GetEnabledJobs(ctx context.Context) []string {
	enabledJobs, err := onlineconf.GetStrings(ctx, GetConfigPath("jobs", "enabled"), []string{})
	if err != nil {
		zlog.Ctx(ctx).Error().Err(err).Msg("get enabled jobs")

		return []string{}
	}

	return enabledJobs
}

func GetBatchSize(ctx context.Context) uint32 {
	batchSize, err := onlineconf.GetInt(ctx, GetConfigPath("batch_size"), DefaultBatchSize)
	if err != nil {
		zlog.Ctx(ctx).Error().Err(err).Msg("get batch size")

		return DefaultBatchSize
	}

	if batchSize <= 0 || batchSize > math.MaxUint32 {
		zlog.Ctx(ctx).Error().Err(err).Msg("invalid batch size")

		return DefaultBatchSize
	}

	return uint32(batchSize)
}

func GetConfigPath(key ...string) string{
	components := []string{constant.ServiceName, "worker", WorkerName}
	components = append(components, key...)

	return onlineconf.MakePath(components...)
}

func (w *Worker) JobStarter(ctx context.Context, task daemon.ITask) (err error) {
	ocPrefix := GetConfigPath()
	ctxJob, cancel, err := reqctx.CreateContext(ctx, ctx, ocPrefix, "job")
	if err != nil {
		{{ .Logger.ErrorMsg "ctx" "err" "Failed to create job context" "Str(nameFieldLogger, WorkerName)" }}
		return err
	}
	{{ .Logger.ReWrap "ctx" "ctxJob" "ocPrefix" "\"job\"" }}
	{{ .Logger.UpdateContext "ctxJob" "Str(\"taskID\", task.GetID(ctxJob)).Str(nameFieldLogger, WorkerName)" }}

	err = errors.New("unexpected error")

	defer func() {
		err := recover()
		if err != nil {
			{{ .Logger.ErrorMsg "ctxJob" "errors.New(\"panic catch\")" "panic" "Interface(\"panic error\", err)" "Str(\"Stack\", strings.Replace(strings.Replace(string(debug.Stack()), \"\\n\\t/\", \" --> /\", -1), \"\\n\", \" => \", -1))" }}
		}

		cancel()
	}()

	err = task.Do(ctxJob, w.Srv)
	if err != nil {
		{{ .Logger.ErrorMsg "ctxJob" "err" "Error job starter" "Str(nameFieldLogger, WorkerName)" "Str(\"taskID\", task.GetID(ctxJob))"}}
	}

	return
}

// Run - start worker
func (w *Worker) Run(ctx context.Context, errGr *errgroup.Group) {
	// initialization worker
	errGr.Go(func() error {
		{{ .Logger.InfoMsg "ctx" "Run worker" "Str(nameFieldLogger, WorkerName)" }}

		timer := time.NewTimer(time.Millisecond * 500)
		iterNum := 1

	JOB:
		for {
			select {
			case <-timer.C:
				iterNum++
				if iterNum % 100 == 0 {
					{{ .Logger.InfoMsg "ctx" "worker iteration" "Int(\"iterNum\", iterNum)" "Str(nameFieldLogger, WorkerName)" }}
				}

				tasks, jobState, err := w.GetTasks(ctx, w.jobState)
				if err != nil {
					{{ .Logger.ErrorMsg "ctx" "err" "Error get tasks" "Str(nameFieldLogger, WorkerName)" }}
					timer = time.NewTimer(ErrorTimeout)
					continue
				}

				w.jobState = jobState

				if tasks == nil {
					{{ .Logger.InfoMsg "ctx" "tasks is nill. Probable new cycle started" "Str(nameFieldLogger, WorkerName)" }}
					timer = time.NewTimer(NewCycleTimeout)
					continue
				}

				if len(tasks) == 0 {
					{{ .Logger.InfoMsg "ctx" "no tasks to run" "Str(nameFieldLogger, WorkerName)" }}
					timer = time.NewTimer(NextIterationTimeout)
					continue
				}

				MaxWorkers, err := onlineconf.GetInt(ctx, GetConfigPath("max_workers"), 5)
				if err != nil {
					{{ .Logger.ErrorMsg "ctx" "err" "Error get max_workers config" "Str(nameFieldLogger, WorkerName)" }}
					MaxWorkers = 5 // default value
				}

				var wgWorkers errgroup.Group

				tasksChan := make(chan daemon.ITask)

				for i := 0; i < int(MaxWorkers); i++ {
					wgWorkers.Go(func() error {
						for task := range tasksChan {
							if err := w.JobStarter(ctx, task); err != nil {
								{{ .Logger.ErrorMsg "ctx" "err" "Error job starter" "Str(nameFieldLogger, WorkerName)" "Str(\"taskID\", task.GetID(ctx))"}}
							}
						}

						return nil
					})
				}

				for _, task := range tasks {
					tasksChan <- task
				}

				close(tasksChan)

				if err := wgWorkers.Wait(); err != nil {
					{{ .Logger.ErrorMsg "ctx" "err" "Worker pool error" "Str(nameFieldLogger, WorkerName)" }}
				}

				{{ .Logger.DebugMsg "ctx" "worker finished cycle" }}
				timer = time.NewTimer(NextIterationTimeout)
			case <-ctx.Done():
				break JOB
			}
		}

		{{ .Logger.InfoMsg "ctx" "worker stopped" "Str(nameFieldLogger, WorkerName)" }}

		return nil
	})
}

// ShutdownHTTP shutting down worker
func (w *Worker) Shutdown(_ context.Context) error {
	return nil
}

// GracefulStop do graceful stop worker
func (w *Worker) GracefulStop(_ context.Context) (<-chan struct{}, error) {
	stopped := make(chan struct{})
	close(stopped)

	return stopped, nil
}
