package {{ .Kafka.Name | ToLower }}

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/Educentr/go-project-starter-runtime/pkg/ds"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/segmentio/kafka-go"
	"golang.org/x/sync/errgroup"
	{{ .Logger.Import }}
)

const clientName = "{{ .Kafka.ClientName }}"
const asyncQueueSize = 1000
const asyncPublishTimeout = 5 * time.Second

// asyncMessage represents a message to be published asynchronously
type asyncMessage struct {
	topic string
	key   []byte
	value []byte
}

// Producer is a Kafka producer for {{ .Kafka.Name }}
type Producer struct {
	serviceName string
	writer      *kafka.Writer
	metrics     *Metrics
	eventTopics map[string]string
	disabled    bool
	asyncChan   chan asyncMessage
	stopChan       chan struct{}
	closeOnce      sync.Once
	writerCloseOnce sync.Once
}

// Create returns a new Producer instance
func Create() *Producer {
	return &Producer{}
}

// Name returns the driver name
func (p *Producer) Name() string {
	return "KafkaProducer_{{ .Kafka.Name }}"
}

// Init initializes the producer connection
func (p *Producer) Init(ctx context.Context, serviceName string, _ ds.ServerBucket, registry *prometheus.Registry) error {
	p.serviceName = serviceName

	brokers, err := getBrokers(ctx, serviceName)
	if err != nil {
		{{ .Logger.WarnMsg "ctx" "kafka producer disabled: brokers not configured" "err::err" (printf "str::producer::\"%s\"" .Kafka.Name) }}
		p.disabled = true
		return nil
	}

	transport, err := buildTransport(ctx, serviceName)
	if err != nil {
		return fmt.Errorf("build transport: %w", err)
	}

	p.eventTopics, err = loadEventTopics(ctx, serviceName)
	if err != nil {
		return fmt.Errorf("load event topics: %w", err)
	}

	p.writer = &kafka.Writer{
		Addr:      kafka.TCP(brokers...),
		Transport: transport,
		Balancer:  &kafka.LeastBytes{},
	}

	p.metrics = NewMetrics(registry, "{{ .Kafka.Name | ToLower }}")

	// Initialize async channels
	p.asyncChan = make(chan asyncMessage, asyncQueueSize)
	p.stopChan = make(chan struct{})

	// Warm up connection by fetching metadata
	if err := p.warmup(ctx, brokers[0], transport); err != nil {
		{{ .Logger.WarnMsg "ctx" "kafka warmup failed, first request may be slow" "err::err" (printf "str::producer::\"%s\"" .Kafka.Name) }}
	} else {
		{{ .Logger.InfoMsg "ctx" "kafka connection warmed up" (printf "str::producer::\"%s\"" .Kafka.Name) "str::broker::brokers[0]" }}
	}

	return nil
}

// warmup establishes connection to broker and fetches metadata to pre-warm the connection pool
func (p *Producer) warmup(ctx context.Context, broker string, transport *kafka.Transport) error {
	dialer := &kafka.Dialer{
		Timeout:       10 * time.Second,
		DualStack:     true,
		SASLMechanism: transport.SASL,
		TLS:           transport.TLS,
	}

	conn, err := dialer.DialContext(ctx, "tcp", broker)
	if err != nil {
		return fmt.Errorf("dial broker: %w", err)
	}
	defer conn.Close()

	// Fetch brokers metadata to warm up connection
	_, err = conn.Brokers()
	if err != nil {
		return fmt.Errorf("fetch brokers: %w", err)
	}

	return nil
}

// IsDisabled returns true if producer is disabled (no kafka configured)
func (p *Producer) IsDisabled() bool {
	return p.disabled
}

// Run starts the producer and async worker
func (p *Producer) Run(ctx context.Context, _ *errgroup.Group) {
	if p.disabled {
		return
	}

	// Start async worker
	go p.asyncWorker(ctx)
}

// asyncWorker processes async messages from the channel
func (p *Producer) asyncWorker(ctx context.Context) {
	{{ .Logger.SubContext "ctx" (printf "str::producer::\"%s\"" .Kafka.Name) }}
	{{ .Logger.InfoMsg "ctx" "kafka async worker started" }}

	for {
		select {
		case msg, ok := <-p.asyncChan:
			if !ok {
				{{ .Logger.InfoMsg "ctx" "kafka async worker stopped: channel closed" }}
				return
			}
			p.processAsyncMessage(ctx, msg)
		case <-p.stopChan:
			// Drain remaining messages with timeout
			p.drainMessages(ctx)
			{{ .Logger.InfoMsg "ctx" "kafka async worker stopped" }}
			return
		}
	}
}

// processAsyncMessage publishes a single async message
func (p *Producer) processAsyncMessage(parentCtx context.Context, msg asyncMessage) {
	ctx, cancel := context.WithTimeout(parentCtx, asyncPublishTimeout)
	defer cancel()

	err := p.writer.WriteMessages(ctx, kafka.Message{
		Topic: msg.topic,
		Key:   msg.key,
		Value: msg.value,
	})
	if err != nil {
		{{ .Logger.ErrorMsg "parentCtx" "err" "failed to publish async message" "str::topic::msg.topic" }}
		p.metrics.PublishError(msg.topic)
	} else {
		p.metrics.PublishSuccess(msg.topic)
	}
}

// drainMessages processes remaining messages in the channel before shutdown
func (p *Producer) drainMessages(ctx context.Context) {
	timeout := time.After(5 * time.Second)
	for {
		select {
		case msg, ok := <-p.asyncChan:
			if !ok {
				return
			}
			p.processAsyncMessage(ctx, msg)
		case <-timeout:
			remaining := len(p.asyncChan)
			if remaining > 0 {
				{{ .Logger.WarnMsg "ctx" "kafka async worker shutdown: dropped messages" "int::remaining::remaining" }}
			}
			return
		default:
			return
		}
	}
}

// PublishAsync sends a message asynchronously (non-blocking, fire and forget)
func (p *Producer) PublishAsync(topic string, key, value []byte) {
	if p.disabled {
		return
	}

	select {
	case p.asyncChan <- asyncMessage{topic: topic, key: key, value: value}:
		// Message queued
	default:
		// Channel full, drop message
		p.metrics.PublishDropped(topic)
	}
}

// closeWriter safely closes the kafka writer (only once)
func (p *Producer) closeWriter() error {
	var err error
	p.writerCloseOnce.Do(func() {
		if p.writer != nil {
			err = p.writer.Close()
		}
	})
	return err
}

// Shutdown closes the producer connection
func (p *Producer) Shutdown(_ context.Context) error {
	// Signal worker to stop (only once)
	p.closeOnce.Do(func() {
		if p.stopChan != nil {
			close(p.stopChan)
		}
	})
	return p.closeWriter()
}

// GracefulStop gracefully stops the producer
func (p *Producer) GracefulStop(ctx context.Context) (<-chan struct{}, error) {
	done := make(chan struct{})
	go func() {
		defer close(done)
		// Signal worker to stop and drain messages (only once)
		p.closeOnce.Do(func() {
			if p.stopChan != nil {
				close(p.stopChan)
			}
		})
		// Give worker time to drain
		time.Sleep(100 * time.Millisecond)
		p.closeWriter()
	}()
	return done, nil
}
